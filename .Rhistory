# Produce a matrix corresponding to the 19 predictors and also automatically transforms any qualitative variables into dummy variables
Hitters=na.omit(Hitters)
# Chapter 6 Lab 2: Ridge Regression and the Lasso
# Call necesaary packages
library(ISLR)
library(glmnet)
# Produce a matrix corresponding to the 19 predictors and also automatically transforms any qualitative variables into dummy variables
Hitters=na.omit(Hitters)
x=model.matrix(Salary~.,Hitters)[,-1]
y=Hitters$Salary
x
y
dim(x)
plot(cv.out)
# Chapter 6 Lab 2: Ridge Regression and the Lasso
# Call necesaary packages
library(ISLR)
library(glmnet)
# Produce a matrix corresponding to the 19 predictors and also automatically transforms any qualitative variables into dummy variables
Hitters=na.omit(Hitters)
x=model.matrix(Salary~.,Hitters)[,-1]
y=Hitters$Salary
# Set a tuning paramter vector of length 100
grid=10^seq(10,-2,length=100)
# fit the ridge regression model by setting alpha = 0
ridge.mod=glmnet(x,y,alpha=0,lambda=grid)
# Check the dimension of the matrix storing the regression coefficients
dim(coef(ridge.mod))
# Check the 50th lambda value
ridge.mod$lambda[50]
# Display the corresponding paramter estimates when lambda = 11497.57
coef(ridge.mod)[,50]
# ?
sqrt(sum(coef(ridge.mod)[-1,50]^2))
# Try another value of lambda
ridge.mod$lambda[60]
coef(ridge.mod)[,60]
sqrt(sum(coef(ridge.mod)[-1,60]^2))
# Use predict function to show the result when lambda = 50
predict(ridge.mod,s=50,type="coefficients")[1:20,]
# Prepare the training and testing data sets
set.seed(1)
train=sample(1:nrow(x), nrow(x)/2)
test=(-train)
y.test=y[test]
# Fit ridge regression model
ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid, thresh=1e-12)
ridge.pred=predict(ridge.mod,s=4,newx=x[test,])
mean((ridge.pred-y.test)^2)
mean((mean(y[train])-y.test)^2)
ridge.pred=predict(ridge.mod,s=1e10,newx=x[test,])
mean((ridge.pred-y.test)^2)
ridge.pred=predict(ridge.mod,s=0,newx=x[test,],exact=T)
mean((ridge.pred-y.test)^2)
lm(y~x, subset=train)
predict(ridge.mod,s=0,exact=T,type="coefficients")[1:20,]
# Perform cross validation
set.seed(1)
cv.out=cv.glmnet(x[train,],y[train],alpha=0)
plot(cv.out)
bestlam=cv.out$lambda.min
bestlam
log(bestlam)
ridge.pred=predict(ridge.mod,s=bestlam,newx=x[test,])
mean((ridge.pred-y.test)^2)
out=glmnet(x,y,alpha=0)
predict(out,type="coefficients",s=bestlam)[1:20,]
summary(out)
out
ridge.pred=predict(ridge.mod,s=0,newx=x[test,],exact=T)
mean((ridge.pred-y.test)^2)
lm(y~x, subset=train)
predict(ridge.mod,s=0,exact=T,type="coefficients")[1:20,]
# Chapter 6 Lab 2: Ridge Regression and the Lasso
# Call necesaary packages
library(ISLR)
library(glmnet)
# Produce a matrix corresponding to the 19 predictors and also automatically transforms any qualitative variables into dummy variables
Hitters=na.omit(Hitters)
x=model.matrix(Salary~.,Hitters)[,-1]
y=Hitters$Salary
# Set a tuning paramter vector of length 100
grid=10^seq(10,-2,length=100)
# fit the ridge regression model by setting alpha = 0
ridge.mod=glmnet(x,y,alpha=0,lambda=grid)
# Check the dimension of the matrix storing the regression coefficients
dim(coef(ridge.mod))
# Check the 50th lambda value
ridge.mod$lambda[50]
# Display the corresponding paramter estimates when lambda = 11497.57
coef(ridge.mod)[,50]
# ?
sqrt(sum(coef(ridge.mod)[-1,50]^2))
# Try another value of lambda
ridge.mod$lambda[60]
coef(ridge.mod)[,60]
sqrt(sum(coef(ridge.mod)[-1,60]^2))
# Use predict function to show the result when lambda = 50
predict(ridge.mod,s=50,type="coefficients")[1:20,]
# Prepare the training and testing data sets
set.seed(1)
train=sample(1:nrow(x), nrow(x)/2)
test=(-train)
y.test=y[test]
# Fit ridge regression model
ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid, thresh=1e-12)
ridge.pred=predict(ridge.mod,s=4,newx=x[test,])
mean((ridge.pred-y.test)^2)
mean((mean(y[train])-y.test)^2)
ridge.pred=predict(ridge.mod,s=1e10,newx=x[test,])
mean((ridge.pred-y.test)^2)
ridge.pred=predict(ridge.mod,s=0,newx=x[test,],exact=T)
mean((ridge.pred-y.test)^2)
lm(y~x, subset=train)
predict(ridge.mod,s=0,exact=T,type="coefficients")[1:20,]
lasso.mod=glmnet(x[train,],y[train],alpha=1,lambda=grid)
plot(lasso.mod)
library(tree)
library(ISLR)
attach(Carseats)
High=ifelse(Sales<=8,"No","Yes")
Sales
#  Fit a classification tree in order to predict High using all variables but Sales.
tree.carseats=tree(High~.-Sales,Carseats)
summary(tree.carseats)
library(tree)
install.packages("tree")
library(tree)
#  Fit a classification tree in order to predict High using all variables but Sales.
tree.carseats=tree(High~.-Sales,Carseats)
summary(tree.carseats)
library(tree)
library(ISLR)
attach(Carseats)
High=ifelse(Sales<=8,"No","Yes")
Carseats=data.frame(Carseats,High)
#  Fit a classification tree in order to predict High using all variables but Sales.
tree.carseats=tree(High~.-Sales,Carseats)
summary(tree.carseats)
# Plot the decision tree
plot(tree.carseats)
# Display the node labels
text(tree.carseats,pretty=0)
# Print output corresponding to each branch of the tree.
tree.carseats
library(tree)
library(ISLR)
attach(Carseats)
High=ifelse(Sales<=8,"No","Yes")
Carseats=data.frame(Carseats,High)
#  Fit a classification tree in order to predict High using all variables but Sales.
tree.carseats=tree(High~.-Sales,Carseats)
summary(tree.carseats)
# Plot the decision tree
plot(tree.carseats)
# Display the node labels
text(tree.carseats,pretty=0)
library(tree)
library(ISLR)
attach(Carseats)
High=ifelse(Sales<=8,"No","Yes")
Carseats=data.frame(Carseats,High)
#  Fit a classification tree in order to predict High using all variables but Sales.
tree.carseats=tree(High~.-Sales,Carseats)
summary(tree.carseats)
# Plot the decision tree
plot(tree.carseats)
# Display the node labels
text(tree.carseats,pretty=0)
# Print output corresponding to each branch of the tree.
tree.carseats
# Print output corresponding to each branch of the tree.
tree.carseats
# Predict the class membership
tree.pred=predict(tree.carseats,Carseats.test,type="class")
# Print output corresponding to each branch of the tree.
tree.carseats
# Split the observations into a training set and a test set, build the tree using the training set, and evaluate its performance on the test data.
set.seed(2)
train=sample(1:nrow(Carseats), 200)
Carseats.test=Carseats[-train,]
High.test=High[-train]
tree.carseats=tree(High~.-Sales,Carseats,subset=train)
# Predict the class membership
tree.pred=predict(tree.carseats,Carseats.test,type="class")
table(tree.pred,High.test)
(86+57)/200
# Use cross-validation to prune the tree
set.seed(3)
cv.carseats=cv.tree(tree.carseats,FUN=prune.misclass)
names(cv.carseats)
cv.carseats
par(mfrow=c(1,2))
plot(cv.carseats$size,cv.carseats$dev,type="b")
plot(cv.carseats$k,cv.carseats$dev,type="b")
prune.carseats=prune.misclass(tree.carseats,best=9)
plot(prune.carseats)
text(prune.carseats,pretty=0)
tree.pred=predict(prune.carseats,Carseats.test,type="class")
table(tree.pred,High.test)
(94+60)/200
prune.carseats=prune.misclass(tree.carseats,best=15)
plot(prune.carseats)
text(prune.carseats,pretty=0)
tree.pred=predict(prune.carseats,Carseats.test,type="class")
table(tree.pred,High.test)
(86+62)/200
library(MASS)
set.seed(1)
train = sample(1:nrow(Boston), nrow(Boston)/2)
tree.boston=tree(medv~.,Boston,subset=train)
summary(tree.boston)
plot(tree.boston)
text(tree.boston,pretty=0)
cv.boston=cv.tree(tree.boston)
plot(cv.boston$size,cv.boston$dev,type='b')
prune.boston=prune.tree(tree.boston,best=5)
plot(prune.boston)
text(prune.boston,pretty=0)
yhat=predict(tree.boston,newdata=Boston[-train,])
boston.test=Boston[-train,"medv"]
plot(yhat,boston.test)
abline(0,1)
mean((yhat-boston.test)^2)
prune.boston=prune.tree(tree.boston,best=8)
plot(prune.boston)
text(prune.boston,pretty=0)
library(randomForest)
install.packages("randomForest")
library(randomForest)
set.seed(1)
bag.boston=randomForest(medv~.,data=Boston,subset=train,mtry=13,importance=TRUE)
bag.boston
yhat.bag = predict(bag.boston,newdata=Boston[-train,])
plot(yhat.bag, boston.test)
abline(0,1)
mean((yhat.bag-boston.test)^2)
dim(Boston)
bag.boston=randomForest(medv~.,data=Boston,subset=train,mtry=13,ntree=25)
yhat.bag = predict(bag.boston,newdata=Boston[-train,])
mean((yhat.bag-boston.test)^2)
set.seed(1)
rf.boston=randomForest(medv~.,data=Boston,subset=train,mtry=6,importance=TRUE)
yhat.rf = predict(rf.boston,newdata=Boston[-train,])
mean((yhat.rf-boston.test)^2)
importance(rf.boston)
varImpPlot(rf.boston)
# 6.5.1 Best Subset Selection
# Goal: predict a baseball player???s Salary on the basis of various statistics associated with performance in the previous year.
# Call the ISLR package
library(ISLR)
# View Hitters data
View(Hitters)
# Check variable names
names(Hitters)
# Check column and row numbers (number of variables and observations)
dim(Hitters)
# is.na() is used to identify missing observations
# sum() for counting the number of missing elements
sum(is.na(Hitters$Salary))
# Remove all of the rows that have missing values in any variable
Hitters=na.omit(Hitters)
dim(Hitters)
sum(is.na(Hitters))
# Call the leaps package to perform best subset selection
library(leaps)
# Performs best subset selection by identifying the best model that contains a given number of predictors
# By default, regsubsets() only reports results up to the best 8 variable model.
regfit.full=regsubsets(Salary~.,Hitters)
# Outputs the best set of variables for each model size.
summary(regfit.full)
# Force it to try all possible number of variables
regfit.full=regsubsets(Salary~.,data=Hitters,nvmax=19)
reg.summary=summary(regfit.full)
# Check elements in the object "regsubsets"
names(reg.summary)
# Changes of R-squared
reg.summary$rsq
# Plotting RSS, adjusted R2, Cp, and BIC for all of the models at once
par(mfrow=c(2,2))
plot(reg.summary$rss,xlab="Number of Variables",ylab="RSS",type="l")
plot(reg.summary$adjr2,xlab="Number of Variables",ylab="Adjusted RSq",type="l")
# Identify the location of the maximum point of a vector
which.max(reg.summary$adjr2)
# Plot the maximum point
points(11,reg.summary$adjr2[11], col="red",cex=2,pch=20)
plot(reg.summary$cp,xlab="Number of Variables",ylab="Cp",type='l')
which.min(reg.summary$cp)
points(10,reg.summary$cp[10],col="red",cex=2,pch=20)
which.min(reg.summary$bic)
plot(reg.summary$bic,xlab="Number of Variables",ylab="BIC",type='l')
points(6,reg.summary$bic[6],col="red",cex=2,pch=20)
# Use the built-in plot() command of the regsubset() function
plot(regfit.full,scale="r2")
plot(regfit.full,scale="adjr2")
plot(regfit.full,scale="Cp")
plot(regfit.full,scale="bic")
coef(regfit.full,6)
#####################################################################################################################################
# 6.5.2 Forward and Backward Stepwise Selection
# Perfrom forward stepwise selection
regfit.fwd=regsubsets(Salary~.,data=Hitters,nvmax=19,method="forward")
summary(regfit.fwd)
# Perfrom backward stepwise selection
regfit.bwd=regsubsets(Salary~.,data=Hitters,nvmax=19,method="backward")
summary(regfit.bwd)
# Retrieve coefficient estimates for the 7 variable model
coef(regfit.full,7)
coef(regfit.fwd,7)
coef(regfit.bwd,7)
#####################################################################################################################################
# 6.5.3 Choosing Among Models Using the Validation Set Approach and Cross-Validation
set.seed(1)
# Create a random vector, train, of elements equal to TRUE if the corresponding observation is in the training set, and FALSE otherwise.
train=sample(c(TRUE,FALSE), nrow(Hitters),rep=TRUE)
test=(!train)
regfit.best=regsubsets(Salary~.,data=Hitters[train,],nvmax=19)
# Building an "X" matrix from data
test.mat=model.matrix(Salary~.,data=Hitters[test,])
# Prepare a vector to store values of test MSE
val.errors=rep(NA,19)
for(i in 1:19){
# for each model size i, extract the coefficients from regfit.best for the best model of that size
coefi=coef(regfit.best,id=i)
# compute the predicted values of yhat
pred=test.mat[,names(coefi)]%*%coefi
# Calculate test MSE for a model of size i
val.errors[i]=mean((Hitters$Salary[test]-pred)^2)
}
val.errors
which.min(val.errors)
coef(regfit.best,10)
# Write our own predict method
predict.regsubsets=function(object,newdata,id,...){
form=as.formula(object$call[[2]])
mat=model.matrix(form,newdata)
coefi=coef(object,id=id)
xvars=names(coefi)
mat[,xvars]%*%coefi
}
regfit.best=regsubsets(Salary~.,data=Hitters,nvmax=19)
coef(regfit.best,10)
# Perform 10-fold cross validation
k=10
set.seed(1)
# Allocate each observation to one of k = 10 folds
folds=sample(1:k,nrow(Hitters),replace=TRUE)
# Creat an empty matrix to store the cross validation results
# the (i,j)th element corresponds to the test MSE for the ith cross-validation fold for the best j-variable model
cv.errors=matrix(NA,k,19, dimnames=list(NULL, paste(1:19)))
# The loop which performs cross-validation
for(j in 1:k){
best.fit=regsubsets(Salary~.,data=Hitters[folds!=j,],nvmax=19)
for(i in 1:19){
pred=predict(best.fit,Hitters[folds==j,],id=i)
cv.errors[j,i]=mean( (Hitters$Salary[folds==j]-pred)^2)
}
}
# Average over the columns across the 10 validations
mean.cv.errors=apply(cv.errors,2,mean)
mean.cv.errors
par(mfrow=c(1,1))
plot(mean.cv.errors,type='b')
reg.best=regsubsets(Salary~.,data=Hitters, nvmax=19)
coef(reg.best,11)
# Chapter 6 Lab 2: Ridge Regression and the Lasso
# Call necesaary packages
library(ISLR)
library(glmnet)
# Produce a matrix corresponding to the 19 predictors and also automatically transforms any qualitative variables into dummy variables
Hitters=na.omit(Hitters)
x=model.matrix(Salary~.,Hitters)[,-1]
y=Hitters$Salary
# Set a tuning paramter vector of length 100
grid=10^seq(10,-2,length=100)
# fit the ridge regression model by setting alpha = 0
ridge.mod=glmnet(x,y,alpha=0,lambda=grid)
# Check the dimension of the matrix storing the regression coefficients
dim(coef(ridge.mod))
# Check the 50th lambda value
ridge.mod$lambda[50]
# Display the corresponding paramter estimates when lambda = 11497.57
coef(ridge.mod)[,50]
# ?
sqrt(sum(coef(ridge.mod)[-1,50]^2))
# Try another value of lambda
ridge.mod$lambda[60]
coef(ridge.mod)[,60]
sqrt(sum(coef(ridge.mod)[-1,60]^2))
# Use predict function to show the result when lambda = 50
predict(ridge.mod,s=50,type="coefficients")[1:20,]
# Prepare the training and testing data sets
set.seed(1)
train=sample(1:nrow(x), nrow(x)/2)
test=(-train)
y.test=y[test]
# Fit ridge regression model
ridge.mod=glmnet(x[train,],y[train],alpha=0,lambda=grid, thresh=1e-12)
ridge.pred=predict(ridge.mod,s=4,newx=x[test,])
mean((ridge.pred-y.test)^2)
mean((mean(y[train])-y.test)^2)
ridge.pred=predict(ridge.mod,s=1e10,newx=x[test,])
mean((ridge.pred-y.test)^2)
ridge.pred=predict(ridge.mod,s=0,newx=x[test,],exact=T)
mean((ridge.pred-y.test)^2)
lm(y~x, subset=train)
predict(ridge.mod,s=0,exact=T,type="coefficients")[1:20,]
# Perform cross validation
set.seed(1)
cv.out=cv.glmnet(x[train,],y[train],alpha=0)
plot(cv.out)
bestlam=cv.out$lambda.min
bestlam
ridge.pred=predict(ridge.mod,s=bestlam,newx=x[test,])
mean((ridge.pred-y.test)^2)
out=glmnet(x,y,alpha=0)
predict(out,type="coefficients",s=bestlam)[1:20,]
lasso.mod=glmnet(x[train,],y[train],alpha=1,lambda=grid)
plot(lasso.mod)
out=glmnet(x,y,alpha=1,lambda=grid)
lasso.coef=predict(out,type="coefficients",s=bestlam)[1:20,]
lasso.coef
lasso.coef[lasso.coef!=0]
dat = read.csv("ks-projects-201801.csv", header = TRUE)
setwd("/Volumes/GoogleDrive/My Drive/Comp3354/HorseRacingHK")
dat = read.csv("ks-projects-201801.csv", header = TRUE)
dat
summary(dat)
?view
?View
View(dat)
df = read.csv("ks-projects-201801.csv", header = TRUE)
df$usd.pledged <- NULL
View(df)
df$goal <- NULL
summary(df$deadline)
describe(df)
?describe
df.describe
str(df$deadline)
str(df)
as.Date(as.character(df$deadline), format="%Y/%m/%d")
as.Date(as.character(df$deadline), format="%Y-%m-%d")
as.Date(as.character(df$launched), format="%Y-%m-%d")
as.Date(as.character(df$deadline), format="%Y-%m-%d") - as.Date(as.character(df$launched), format="%Y-%m-%d")
as.Date(as.character(df$deadline), format="%Y-%m-%d") -as.Date(as.character(df$launched), format="%Y-%m-%d")
as.Date(as.character(df$launched), format="%Y-%m-%d h:m:s")
as.Date(as.character(df$launched), format="%Y-%m-%d H:m:s")
as.POSIXct(as.character(df$launched), format="%Y-%m-%d H:m:s")
as.POSIXct(as.character(df$launched))
round_date(as.POSIXct(as.character(df$launched)), "day")
install.packages("lubridate")
?round_date
?lubridate
??lubridate
library(lubridate)
round_date()
round_date(as.POSIXct(as.character(df$launched)), "day")
as.Date(as.character(df$deadline), format="%Y-%m-%d") -round_date(as.POSIXct(as.character(df$launched)), "day")
as.POSIXct.Date(as.character(df$deadline), format="%Y-%m-%d") -round_date(as.POSIXct(as.character(df$launched)), "day")
as.POSIXct(as.character(df$deadline), format="%Y-%m-%d") -round_date(as.POSIXct(as.character(df$launched)), "day")
difftime(as.POSIXct(as.character(df$deadline), format="%Y-%m-%d"), round_date(as.POSIXct(as.character(df$launched)), "day"))
difftime(as.POSIXct(as.character(df$deadline), format="%Y-%m-%d"), round_date(as.POSIXct(as.character(df$launched)), "day"), units='days')
difftime(as.POSIXct(as.character(df$deadline), format="%Y-%m-%d"), round_date(as.POSIXct(as.character(df$launched)), "day"), units='days') + 1
startday = round_date(as.POSIXct(as.character(df$launched)), "day")
endday = as.POSIXct(as.character(df$deadline), format="%Y-%m-%d")
df$duration <- difftime(endday, startday, units='days') + 1
View(df)
summary(df$state)
summ = summary(df$state)
sum(summ)
summ = summ/sum(summ)
summ
#removing
df<- df[!(df$state=="undefined")]
#removing
df<- df[!(df$state=='undefined')]
#removing
df<- df[!(df$state == undefined)]
#removing
df<- df[!(df$state == 'undefined')]
summ = summary(df$state)
summ
sum(summ)
#removing
df<- df[!(df$state == 'undefined')]
#removing
df<- df[!(df$state == grep('undefined'))]
#removing
df<- df[!df$state == "undefined"]
#removing
df<- df[!df$state == "undefined", ]
summary(df$state)
#removing
df<- df[(df$state == "live" | df$state == "failed" | df$state == "live" ), ]
summary(df$state)
#getting dataset
og = read.csv("ks-projects-201801.csv", header = TRUE)
df = og
#remove usd.pledged and goal columns
df$usd.pledged <- NULL
df$goal <- NULL
#calculating duration column
startday = round_date(as.POSIXct(as.character(df$launched)), "day")
endday = as.POSIXct(as.character(df$deadline), format="%Y-%m-%d")
df$duration <- difftime(endday, startday, units='days') + 1
#removing
df<- df[(df$state == "canceled" | df$state == "failed" | df$state == "live" ), ]
summary(df$state)
sum(summary(df$state))
#write cleaned data to file
write.csv(df, file = "cleaned-ks-data.csv")
